<!DOCTYPE html><!--  This site was created in Webflow. http://www.webflow.com  -->
<!--  Last Published: Tue Nov 17 2020 15:53:36 GMT+0000 (Coordinated Universal Time)  -->
<html data-wf-page="5fac074bd8bc94426a482e03" data-wf-site="5fac074a6b2e910cf4d1b21c">
<head>
  <meta charset="utf-8">
  <title>impersonator_plus_plus</title>
  <meta content="impersonator_plus_plus" property="og:title">
  <meta content="impersonator_plus_plus" property="twitter:title">
  <meta content="width=device-width, initial-scale=1" name="viewport">
  <meta content="Webflow" name="generator">
  <link href="../css/normalize.css" rel="stylesheet" type="text/css">
  <link href="../css/webflow.css" rel="stylesheet" type="text/css">
  <link href="../css/piaos-business-starter.webflow.css" rel="stylesheet" type="text/css">
  <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
  <script type="text/javascript">WebFont.load({  google: {    families: ["Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic"]  }});</script>
  <!-- [if lt IE 9]><script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js" type="text/javascript"></script><![endif] -->
  <script type="text/javascript">!function(o,c){var n=c.documentElement,t=" w-mod-";n.className+=t+"js",("ontouchstart"in o||o.DocumentTouch&&c instanceof DocumentTouch)&&(n.className+=t+"touch")}(window,document);</script>
  <link href="../images/favicon.ico" rel="shortcut icon" type="image/x-icon">
  <link href="../images/webclip.png" rel="apple-touch-icon">

  <!-- KaTeX -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
  <!-- The loading of KaTeX is deferred to speed up page rendering -->
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
  <!-- To automatically render math in text elements, include the auto-render extension: -->
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
      onload="renderMathInElement(document.body);"></script>
</head>
<body class="body">
  <div data-collapse="medium" data-animation="default" data-duration="400" role="banner" class="navigation w-nav">
    <div class="navigation-wrap">
      <a href="../index.html" class="logo-link w-nav-brand">
        <div class="text-block">impersonator</div>
      </a>
      <div class="menu">
        <nav role="navigation" class="navigation-items w-nav-menu">
          <a href="../index.html" class="navigation-item w-nav-link">HOME</a>
          <a href="../projects.html" class="navigation-item w-nav-link">PrOJECTS</a>
          <a href="https://discuss.impersonator.org/" target="_blank" class="navigation-item w-nav-link">DISCUSS</a>
        </nav>
        <div class="menu-button w-nav-button"><img src="../images/menu-icon_1menu-icon.png" width="22" alt="" class="menu-icon"></div>
      </div>
      <a href="mailto:impersonator.org@gmail.com?subject=Hi" class="button cc-contact-us w-inline-block">
        <div>Contact US</div>
      </a>
    </div>
  </div>
  <div class="section cc-home-wrap">
    <div class="project-overview-header">
      <div class="intro-content">
        <div class="heading-jumbo"><strong>Impersonator++</strong><br></div>
        <div class="text-block-2"><strong class="bold-text-2">Liquid Warping GAN with Attention: A UniÔ¨Åed Framework for Human Image Synthesis</strong><br></div>
        <div class="text-block-3">Wen Liu, Zhixin Piao, Zhi Tu, Wenhan Luo, Lin Ma, Shenghua Gao</div>
        <div class="div-block-2">
          <a href="https://arxiv.org/pdf/2011.09055" target="_blank" class="button-3 w-button">Paper</a>
          <a href="https://github.com/iPERDance/iPERCore" target="_blank" class="button-3 w-button">Code</a>
          <a href="https://svip-lab.github.io/dataset/iPER_dataset.html" target="_blank" class="button-3 w-button">Dataset</a>
          <a href="https://discuss.impersonator.org/" target="_blank" class="button-3 w-button">Forum</a>
          <a href="#" class="button-3 w-button">Application (iPER-Dance) (Coming Soon)</a>
        </div>
      </div>
    </div>
  </div>
  <div class="section">
    <div class="container-2 w-container"><img src="../images/motion_results.png" loading="lazy" sizes="(max-width: 479px) 93vw, (max-width: 767px) 96vw, 94vw" srcset="../images/motion_results-p-500.png 500w, ../images/motion_results-p-800.png 800w, ../images/motion_results-p-1080.png 1080w, ../images/motion_results-p-1600.png 1600w, ../images/motion_results-p-2000.png 2000w, ../images/motion_results.png 2888w" alt="">
      <div>
        <h2>Abstract</h2>
        <div>We tackle human image synthesis, including human motion imitation, appearance transfer, and novel view synthesis, within a unified framework. It means that the model, once being trained, can be used to handle all these tasks. The existing task-specific methods mainly use 2D keypoints (pose) to estimate the human body structure. However, they only express the position information with no abilities to characterize the personalized shape of the person and model the limb rotations. In this paper, we propose to use a 3D body mesh recovery module to disentangle the pose and shape. It can not only model the joint location and rotation but also characterize the personalized body shape. To preserve the source information, such as texture, style, color, and face identity, we propose an Attentional Liquid Warping GAN with Attentional Liquid Warping Block (AttLWB) that propagates the source information in both image and feature spaces to the synthesized reference. Specifically, the source features are extracted by a denoising convolutional auto-encoder for characterizing the source identity well. Furthermore, our proposed method can support a more flexible warping from multiple sources. To further improve the generalization ability of the unseen source images, a one/few-shot adversarial learning is applied. In detail, it firstly trains a model in an extensive training set. Then, it finetunes the model by one/few-shot unseen image(s) in a self-supervised way to generate high-resolution (\(512 \times 512\) and \(1024 \times 1024\)) results. Also, we build a new dataset, namely Impersonator (iPER) dataset, for the evaluation of human motion imitation, appearance transfer, and novel view synthesis. Extensive experiments demonstrate the effectiveness of our methods in terms of preserving face identity, shape consistency, and clothes details. </div>
      </div>
    </div>
  </div>
  <div class="section">
    <div class="container">
      <div class="project-pics">
        <div>
          <h2>FrameWork Overview<br></h2><img src="../images/training.png" width="920" sizes="(max-width: 479px) 93vw, (max-width: 767px) 96vw, 94vw" srcset="../images/training-p-500.png 500w, ../images/training-p-1080.png 1080w, ../images/training-p-1600.png 1600w, ../images/training.png 2166w" alt="" class="detail-image">
          <p>The training pipeline of our method. We randomly sample a pair of images from a video, denoting the source and the reference image as \(I_{s_i}\) and \(I_r\). <strong>(a)</strong> A body mesh recovery module will estimate the 3D mesh of each image and render their correspondence map, \(C_s\) and \(C_t\); <strong>(b)</strong> The flow composition module will first calculate the transformation flow \(T\) based on two correspondence maps and their projected vertices in the image space. Then it will separate the source image \(I_{s_i}\) into a foreground image \(I^{ft}_{s_i}\) and a masked background \(I_{bg}\). Finally it warps the source image based on the transformation flow \(T\) and produces a warped image \(I_{syn}\); <strong>(c)</strong> In the last GAN module, the generator consists of three streams, which separately generates the background image \(\hat{I}_{bg}\) by \(G_{BG}\), reconstructs the source image \(\hat{I}_s\) by \(G_{SID}\) and synthesizes the target image \(\hat{I}_t\) under the reference condition by \(G_{TSF}\). To preserve the details of the source image, we propose a novel LWB and AttLWB which propagates the source features of \(G_{SID}\) into \(G_{TSF}\) at several layers and preserve the source information, in terms of texture, style and color.

          </p>
        </div>
        <h2>LWB &amp;&amp; AttLWB<br></h2><img src="../images/AttLWB_V2.png" width="920" sizes="(max-width: 479px) 93vw, (max-width: 767px) 96vw, 94vw" srcset="../images/AttLWB_V2-p-800.png 800w, ../images/AttLWB_V2-p-1080.png 1080w, ../images/AttLWB_V2-p-1600.png 1600w, ../images/AttLWB_V2-p-2000.png 2000w, ../images/AttLWB_V2-p-2600.png 2600w, ../images/AttLWB_V2-p-3200.png 3200w, ../images/AttLWB_V2.png 3210w" alt="" class="detail-image">
        <p>Illustration of our LWB and AttLWB. They have the same structure illustrated in <strong>(b)</strong> but with separate AddWB (illustrated in <strong>(a)</strong>) or AttWB (illustrated in <strong>(b)</strong>). <strong>(a)</strong> is the structure of AddWB. Through AddWB, \(\widehat{X}_t^{l}\) is obtained by  aggregation of warped source features and features from \(G_{TSF}\). <strong>(b)</strong> is the shared structure of (Attentional) Liquid Warping Block. \(\{X^{l}_{s_1}, X^{l}_{s_2}, ..., X^{l}_{s_n}\}\) are the feature maps of different sources extracted by \(G_{SID}\) at the \(l^{th}\) layer. \(\{T_{s_1\to t}, T_{s_2\to t},...,T_{s_n\to t}\}\) are the transformation flows from different sources to the target. \(X^{l}_t\) is the feature map of \(G_{TSF}\) at the \(l^{th}\) layer. <strong>(c)</strong> is the architecture of AttWB. Through AttWB, final output features \(\widehat{X}_t^{l}\) is obtained with SPADE by denormalizing feature map from \(G_{TSF}\) with weighted combination of warped source features by a bilinear sampler (BS) with respect to corresponding flow \(T_{s_i\to t}\). 
        </p>
        <h2>Network Architectures<br></h2><img src="../images/network.png" width="920" sizes="(max-width: 479px) 93vw, (max-width: 767px) 96vw, 94vw" srcset="../images/network-p-500.png 500w, ../images/network-p-800.png 800w, ../images/network-p-1080.png 1080w, ../images/network-p-1600.png 1600w, ../images/network-p-2000.png 2000w, ../images/network-p-2600.png 2600w, ../images/network-p-3200.png 3200w, ../images/network.png 6581w" alt="" class="detail-image">
        <p>The details of network architectures of our Attentional Liquid Warping GAN, including the generator and the discriminator. Here \(s\) represents the stride size in convolution and transposed convolution.</p>

        <h2>Results</h2>
            <hr>
            
            <video class="aaa" controls="controls" width="1015">
                <source src="/project_img/impersonator_plus_plus/demo_video/demo_1_512x512.mp4" type="video/mp4">
            </video>

            <video class="aaa" controls="controls" width="1015">
                <source src="/project_img/impersonator_plus_plus/demo_video/demo_2_512x512.mp4" type="video/mp4">
            </video>

            <video class="aaa" controls="controls" width="1015">
                <source src="/project_img/impersonator_plus_plus/demo_video/demo_3_512x512.mp4" type="video/mp4">
            </video>

            <video class="aaa" controls="controls" width="1015">
                <source src="/project_img/impersonator_plus_plus/demo_video/demo_4_512x512.mp4" type="video/mp4">
            </video>

            <video class="aaa" controls="controls" width="1015">
                <source src="/project_img/impersonator_plus_plus/demo_video/demo_5_512x512.mp4" type="video/mp4">
            </video>

            <video class="aaa" controls="controls" width="1015">
                <source src="/project_img/impersonator_plus_plus/demo_video/demo_6_512x512.mp4" type="video/mp4">
            </video>
            <br/><br/>

            <h2>High Resolution Results <small>(Recommended to watch in full screen mode )</small> </h2>
            <hr>
            <h3>1024 x 1024</h3>
            <video class="aaa" controls="controls" width="1015">
                <source src="/project_img/impersonator_plus_plus/demo_video/demo_6_1024x1024.mp4" type="video/mp4">
            </video>
            <br/><br/>
            
            <h3>1920 x 1920</h3>
            <video class="aaa" controls="controls" width="1015">
                <source src="/project_img/impersonator_plus_plus/demo_video/demo_6_1920x1920.mp4" type="video/mp4">
            </video>
      </div>

      <h2>Citation</h2>
                
                If you find this useful, please cite our work as follows:
                <pre style="background-color:#f5f5f5;">
@misc{liu2020liquid,
      title={Liquid Warping GAN with Attention: A Unified Framework for Human Image Synthesis}, 
      author={Wen Liu and Zhixin Piao, Zhi Tu, Wenhan Luo, Lin Ma and Shenghua Gao},
      year={2020},
      eprint={2011.09055},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
              

@InProceedings{lwb2019,
    title={Liquid Warping GAN: A Unified Framework for Human Motion Imitation, Appearance Transfer and Novel View Synthesis},
    author={Wen Liu and Zhixin Piao, Min Jie, Wenhan Luo, Lin Ma and Shenghua Gao},
    booktitle={The IEEE International Conference on Computer Vision (ICCV)},
    year={2019}
}
</pre>
      
    </div>
  </div>
  <div class="section">
    <div class="container">
      <div class="footer-wrap">
        <a href="../index.html" target="_blank" class="webflow-link w-inline-block">
          <div class="paragraph-tiny">¬© 2020 Impersonator.org - All rights reserved</div>
        </a>
      </div>
    </div>
  </div>
  <script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=5fac074a6b2e910cf4d1b21c" type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
  <script src="../js/webflow.js" type="text/javascript"></script>
  <!-- [if lte IE 9]><script src="https://cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif] -->
</body>
</html>